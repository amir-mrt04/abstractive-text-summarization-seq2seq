{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
    
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Ù†ØµØ¨ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù…\n",
        "!pip install --upgrade rouge_score datasets transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGUNgMgljzx2",
        "outputId": "c70b597a-0e10-457c-b6f5-69b74455b43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=59d0e81c699ea76f39d1e3d764f5e2428e124002355c49cdb10e2b23bee9071e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, rouge_score, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, torch, datasets\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 rouge_score-0.1.2 sympy-1.14.0 torch-2.7.1 transformers-4.53.1 triton-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers==4.44.2 datasets==2.21.0 rouge_score torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mH1U1ArL8-p9",
        "outputId": "6c3e9abc-1181-4564-c6b2-061a673ab0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.44.2\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.21.0\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.70.15)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.11.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2025.2)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, tokenizers, transformers, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.1\n",
            "    Uninstalling transformers-4.53.1:\n",
            "      Successfully uninstalled transformers-4.53.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.6.0\n",
            "    Uninstalling datasets-3.6.0:\n",
            "      Successfully uninstalled datasets-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 fsspec-2024.6.1 tokenizers-0.19.1 transformers-4.44.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fsspec",
                  "tokenizers",
                  "transformers"
                ]
              },
              "id": "fab3526b94ad4dd9859e2c5b5b387c61"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from rouge_score import rouge_scorer\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "id": "xYSmHoCRj15m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\").to(device)\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
        "val_dataset = dataset['validation'].select(range(700))\n",
        "train_dataset = dataset['train'].select(range(3000))\n",
        "test_dataset = dataset['test'].select(range(200))\n",
        "\n",
        "def preprocess_data(example):\n",
        "    article = example['article']\n",
        "    summary = example['highlights']\n",
        "    inputs = tokenizer(article, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    outputs = tokenizer(summary, max_length=150, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
        "        \"labels\": outputs[\"input_ids\"].squeeze(),\n",
        "        \"article\": article,\n",
        "        \"highlights\": summary\n",
        "    }\n",
        "\n",
        "val_dataset = val_dataset.map(preprocess_data)\n",
        "train_dataset = train_dataset.map(preprocess_data)\n",
        "test_dataset = test_dataset.map(preprocess_data)\n",
        "\n",
        "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
        "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
        "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"], output_all_columns=True)\n",
        "\n",
        "print(val_dataset[0][\"input_ids\"].shape)\n",
        "print(type(val_dataset[0][\"input_ids\"]))\n",
        "print(\"Article exists:\", \"article\" in val_dataset[0])\n",
        "print(\"Highlights exists:\", \"highlights\" in val_dataset[0])"
      ],
      "metadata": {
        "id": "KdUP3Ow8j94X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "b1751064270b40be838ef0fbe7a2b5dc",
            "543541fe6cfb4e1d9216f372fdbea2e1",
            "0f3d01893baa426799db521a7c31367a",
            "798737cce1034289afe7807099899204",
            "5d3a653750324eb3abdc7e48296853c4",
            "f7ea9f29d51347dca991d31ff7fd7ba9",
            "d8566e617d9d46388d7aaf8865668406",
            "40551c18cd1b4fe489d11e3e161e99a2",
            "c0e0312650e44d01b6b53ae3891615b9",
            "53286a1120c1451fb1a63dbef1a013a4",
            "3bdb0535ef20420aba12a0c7f06df2f6",
            "552658b64b6a43adb06edce63887facb",
            "6851bff4a5db424cb130a53bee5353f8",
            "0db6e9f5b0de4146afe7cf35be6a2b5b",
            "ac0400b962e745fca6ed96061f54415d",
            "2bc22233b3ea47308710478fe7dfbea7",
            "eb8d6b53c7014a59b817fe26a65f8ef2",
            "f3380d026a594766821d69b6692c60bb",
            "6a6557b199394644a86d946e1ae08ed4",
            "71c66dc22d604cc6a4d2922881c92f02",
            "084227d90e4c4dd18bd8efe6e06eca54",
            "7c603068b01648e5a864682dbf0c23e3",
            "a5f9706c2405444bb09f668c1d6b2509",
            "fbf62d12c94f46ba9bb1ef35fc0108da",
            "f88798db0f5f44fc96839d418062b261",
            "6342776f378747dbaca5a3372c6679bc",
            "268257e57cab487998e1e953ca01e85e",
            "e2d2b9189e98464bba2361da0f06a6be",
            "14a60193345a4329b1cd9e05eb43c51f",
            "8f85bb26b150472b853150c818b3a218",
            "9652786ca7cf447bad0621f1ffedf085",
            "c3d97abf7df7418583c4008ca188edca",
            "616b5e02f20148f4bfa2d6412ab5d027"
          ]
        },
        "outputId": "bccbfaf8-a1c6-47de-bf28-7ca425d7e020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1751064270b40be838ef0fbe7a2b5dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "552658b64b6a43adb06edce63887facb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5f9706c2405444bb09f668c1d6b2509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512])\n",
            "<class 'torch.Tensor'>\n",
            "Article exists: True\n",
            "Highlights exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import wandb\n",
        "print(wandb.__version__)\n",
        "print(wandb.run)"
      ],
      "metadata": {
        "id": "a-8Q5N-2kWWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2424286-69db-4698-fe70-965469b540cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20.1\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bart-summarizer-final\",\n",
        "    num_train_epochs=7,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=True,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø§ Early Stopping\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "SS6AeQK-kXAR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "ee039a90-ef8e-4230-93e4-32d13cf8824c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5250' max='5250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5250/5250 38:53, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.009600</td>\n",
              "      <td>0.703391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.806900</td>\n",
              "      <td>0.703704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.783200</td>\n",
              "      <td>0.698573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.618400</td>\n",
              "      <td>0.725979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.514000</td>\n",
              "      <td>0.760027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.524600</td>\n",
              "      <td>0.749106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.431000</td>\n",
              "      <td>0.774560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.356300</td>\n",
              "      <td>0.805544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>0.800901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.322300</td>\n",
              "      <td>0.815752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5250, training_loss=0.7819913431803386, metrics={'train_runtime': 2333.4668, 'train_samples_per_second': 8.999, 'train_steps_per_second': 2.25, 'total_flos': 6402232811520000.0, 'train_loss': 0.7819913431803386, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "\n",
        "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    rouge1_scores = []\n",
        "    rouge2_scores = []\n",
        "    rougeL_scores = []\n",
        "\n",
        "    for pred, ref in zip(predictions, labels):\n",
        "        scores = scorer.score(ref, pred)\n",
        "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
        "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
        "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": np.mean(rouge1_scores),\n",
        "        \"rouge2\": np.mean(rouge2_scores),\n",
        "        \"rougeL\": np.mean(rougeL_scores)\n",
        "    }"
      ],
      "metadata": {
        "id": "3sKr3QjL0yLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ§Ø¨Ø¹ Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ\n",
        "def summarize_text(text, model, tokenizer, max_length=150):\n",
        "    inputs = tokenizer(text, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        min_length=40,\n",
        "        length_penalty=2.0,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def evaluate_model(model, tokenizer, dataset):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    for example in dataset:\n",
        "        pred = summarize_text(example[\"article\"], model, tokenizer)\n",
        "        ref = example[\"highlights\"]\n",
        "        predictions.append(pred)\n",
        "        references.append(ref)\n",
        "\n",
        "\n",
        "    rouge_scores = {\n",
        "        'rouge1': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "        'rouge2': {'precision': [], 'recall': [], 'fmeasure': []},\n",
        "        'rougeL': {'precision': [], 'recall': [], 'fmeasure': []}\n",
        "    }\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        scores = scorer.score(ref, pred)\n",
        "        for metric in ['rouge1', 'rouge2', 'rougeL']:\n",
        "            rouge_scores[metric]['precision'].append(scores[metric].precision)\n",
        "            rouge_scores[metric]['recall'].append(scores[metric].recall)\n",
        "            rouge_scores[metric]['fmeasure'].append(scores[metric].fmeasure)\n",
        "\n",
        "\n",
        "    for metric in rouge_scores:\n",
        "        rouge_scores[metric]['precision'] = np.mean(rouge_scores[metric]['precision'])\n",
        "        rouge_scores[metric]['recall'] = np.mean(rouge_scores[metric]['recall'])\n",
        "        rouge_scores[metric]['fmeasure'] = np.mean(rouge_scores[metric]['fmeasure'])\n",
        "\n",
        "    return rouge_scores\n"
      ],
      "metadata": {
        "id": "S3thGBM6kEqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª\n",
        "rouge_scores = evaluate_model(model, tokenizer, test_dataset)\n",
        "print(\"ROUGE Scores:\", rouge_scores)"
      ],
      "metadata": {
        "id": "45GQYgOUklLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7027a8a-d0de-435e-ab73-2c6486cea0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'rouge1': {'precision': np.float64(0.29272023430880034), 'recall': np.float64(0.38529435439062854), 'fmeasure': np.float64(0.325581251464433)}, 'rouge2': {'precision': np.float64(0.10200851876324048), 'recall': np.float64(0.13802444217357093), 'fmeasure': np.float64(0.11470078304490441)}, 'rougeL': {'precision': np.float64(0.20590357520341362), 'recall': np.float64(0.2732477110973972), 'fmeasure': np.float64(0.22976141479789752)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for metric, scores in rouge_scores.items():\n",
        "    print(f\"{metric}:\")\n",
        "    print(f\"Precision: {scores['precision']}\")\n",
        "    print(f\"Recall: {scores['recall']}\")\n",
        "    print(f\"F1 Score: {scores['fmeasure']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "YCbhzqbK09Iq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a134b5b-ac0e-47ef-901b-aede270c760a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1:\n",
            "Precision: 0.29272023430880034\n",
            "Recall: 0.38529435439062854\n",
            "F1 Score: 0.325581251464433\n",
            "\n",
            "rouge2:\n",
            "Precision: 0.10200851876324048\n",
            "Recall: 0.13802444217357093\n",
            "F1 Score: 0.11470078304490441\n",
            "\n",
            "rougeL:\n",
            "Precision: 0.20590357520341362\n",
            "Recall: 0.2732477110973972\n",
            "F1 Score: 0.22976141479789752\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø±\n",
        "save_dir = \"./bart-summarizer-final\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)"
      ],
      "metadata": {
        "id": "MB6NPq8Lknki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae98694-cb14-4f01-9297-2f27d9f2e847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./bart-summarizer-final/tokenizer_config.json',\n",
              " './bart-summarizer-final/special_tokens_map.json',\n",
              " './bart-summarizer-final/vocab.json',\n",
              " './bart-summarizer-final/merges.txt',\n",
              " './bart-summarizer-final/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dozen or more metal implements are arranged in neat rows on the table next to the bed. They look like something Frankenstein might have had applied to his monster's neck. I begin to feel nervous. What on earth have I got myself into? The pristine white room adds to the feeling that I'm about to undergo major surgery. But I'm not. I'm here to try the wackiest face treatment to hit the beauty scene: the tuning fork facial. Offered at the upmarket Hale Clinic in London and other clinics nationwide, the scary sounding tuning forks are pieces of metal that make different pitched sounds when struck and made to vibrate. Tuned in: Marianne is given the tuning fork treatment . When they are placed on specific parts of the face - the neck, the jowls, forehead and around the eyes - vibrations are said to tighten sagging skin, eradicate dark circles, lessen the appearance of wrinkles and stimulate collagen. The results mean that your face looks younger, brighter and more toned. Some say it's the non-jab equivalent of Botox. The treatment comes from the U.S. - where else? Advocates claim the 'sound waves of the forks vibrate and travel deeply into the body along energy pathways, affecting human physiology and reaching places not easily accessed'. So far, so New Age gibberish. There seems to be no scientific proof that tuning forks can make you look younger, prettier or more rested. It sounds nutty - the kind of thing practised by people who like panpipes and hemp seeds. The UK beauty industryÃ‚Â employs more aÃ‚Â million people andÃ‚Â is worth Ã‚Â£17 bn . I prefer my facials to involve peels, not strange pieces of metal. But while I may be sceptical, I am also, at 37, willing to try anything. Over the past few years, frown lines have begun to appear on my forehead, and my face appears increasingly pale, puffy and bloated. I explain all this to therapist Samara Reid, who's sympathetic. 'What's wonderful about these facials is they improve the appearance of the skin, but also treat the cause of the problem,' she says. 'If you're pale, you probably have poor circulation. The forks can boost blood flow, which will give you a healthier colour.' Samara has been a facial acupuncturist for 20 years, but she has started using the forks on their own and in conjunction with needles. 'I can see my jawline for the first time in a while, and my skin looks plumper and pink, rather than white' The therapies work on the same principle of Chinese acupuncture, which follows the idea that our body's energy - or 'Qi' - flows through 12 main channels called meridians. If this flow is interrupted, it can cause ill health and affect our appearance, causing premature ageing, dry skin and eye bags. Inserting needles or vibrating tuning fork on these trigger points supposedly restores the flow of energy, improving fine lines and circulation, leading to a clearer, rejuvenated complexion. Samara uses them together for a more powerful effect, but for the needle-phobic the forks can be used on their own. Certain forks are designed for different parts of the face and the body - there are dozens of them, with names such as 'Sun', 'Earth' and 'New Moon'. The physical vibrations have an effect on the body, while the sound from the forks is simultaneously soothing. Samara pings one of the forks and puts it up to my ear. The sound is magical, like a xylophone from outer space. She asks me to get on the bed and remove my socks. She explains she will tap my feet with the forks and apply needles to 'bring the energy down for grounding' (whatever that means) before starting on the face and getting the energy flowing all around my body. Samara uses a 'Gold Ohm Unison' tuning fork. She strikes it against a hard disc strapped on her leg, which creates a vibration, before putting the base of the fork on various points on my feet. I can feel a gentle, deep vibration travel through my feet and halfway up my legs. It's a strange, tingly sensation, and builds as she places the fork on more points on my feet. Within two minutes I feel as if I'm floating. She then puts needles in between my toes to 'cleanse the system'. They don't hurt at all. Then she moves to my face. She feels around my jawline and says she can feel I have raised glands. She asks if I get a lot of sore throats, and I say yes. 'The vibration from the forks can help the lymph glands to drain, which will help bring down the swelling,' she says, adding that all she's doing is 'clearing blockages', which will help everything work better. Inserting needles or vibrating tuning fork on these trigger points supposedly restores the flow of energy, improving fine lines and circulation, leading to a clearer, rejuvenated complexion . Marinna finds the physical vibrations have an effect on the body, while the sound from the forks is simultaneously soothing . She also explains that she uses tuning forks to help tighten loose muscle around the jawline. As she puts the base of the 'Earth' fork around my jawline, the vibrations go deep into my head. It feels odd, but also rather lovely. She then puts the forks up to my ears and I hear a clear, deep, bell-like sound that feels as if it's cleaning my mind. All my normal chattering thoughts are gone for a moment. Samara, who is wafting around the room ethereally, as New Aged therapists are wont to do, explains in her soft, slow voice that different forks have different sounds, varying from deep and resonant to high-pitched. She says the 'New Moon' fork is good for wrinkles and crow's feet, because it relaxes the skin. But when she starts talking about how the sounds will 'bring me into alignment with the cycles and rhythms of the cosmos', it feels a step too far. She found the effect was less pronounced the following day - although she still looked better . I begin to feel it is all ridiculous. But then she moves up my face. Samara tells me I have deep lines between my nose and mouth and my cheeks are puffy. She asks if I get a lot of sinus problems. Again, I say yes. She's more thorough than some GPs I've seen. Samara presses the forks along the side of my nose, where the vibrations should help drain the sinuses, and then my eyes, where apparently they will help reduce dark circles. Finally, Samara comes to my forehead. She tells me I have a line forming between my eyebrows, known as the 'suspended sword', which can be caused by fear and concentration. 'Do you frown when you are concentrating?' she asks. I do. 'And do you find yourself feeling frightened quite often?' she asks. Yes! This woman is a mind-reader. And then we're done. It feels as if I've been lying there for a minute, but Samara tells me it's nearly an hour. I feel spaced out. I'm so relaxed it's hard to speak. Apparently, this is normal, the result of feel-good endorphins created when pressure points are stimulated. I'm pleasantly surprised - in the mirror, my face looks less like the Pilsbury Doughboy. I can see my jawline for the first time in a while, and my skin looks plumper and pink, rather than white. The next morning, I take a long, hard look at my face. The effect isn't as pronounced as the day before, but my skin looks smoother and I have more colour. Samara recommends 12 sessions, but most people see a difference after just three or four. At Ã‚Â£90 for an hour, it's not cheap, but it's reminded me of a basic beauty truth: a glowing complexion isn't something to be obtained in an expensive cream - it comes from being healthy inside and out. Samara packs me off with some good advice: drink fresh ginger tea to boost my immune system and try to avoid dairy, which doesn't help if you're prone to congestion, coughs and colds. Maybe I am the hemp seed type after all. I have booked a second appointment. Samara REID, the Hale Clinic, London (020 7631 0156). Experts recommend 12 sessions. At Ã‚Â£90 for an hour, it's not cheap .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Marianne Power triedÃ‚Â the tuning fork facial atÃ‚Â Hale Clinic in London .\n",
        "Utilises tuning forks that make different pitched sounds when struck .\n",
        "Says afterwards her skin looks plumper and pink, rather than white ."
      ],
      "metadata": {
        "id": "xQpwGnfMk21N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ØªØ³Øª Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡\n",
        "article = \"A dozen or more metal implements are arranged in neat rows on the table next to the bed. They look like something Frankenstein might have had applied to his monster's neck. I begin to feel nervous. What on earth have I got myself into? The pristine white room adds to the feeling that I'm about to undergo major surgery. But I'm not. I'm here to try the wackiest face treatment to hit the beauty scene: the tuning fork facial. Offered at the upmarket Hale Clinic in London and other clinics nationwide, the scary sounding tuning forks are pieces of metal that make different pitched sounds when struck and made to vibrate. Tuned in: Marianne is given the tuning fork treatment . When they are placed on specific parts of the face - the neck, the jowls, forehead and around the eyes - vibrations are said to tighten sagging skin, eradicate dark circles, lessen the appearance of wrinkles and stimulate collagen. The results mean that your face looks younger, brighter and more toned. Some say it's the non-jab equivalent of Botox. The treatment comes from the U.S. - where else? Advocates claim the 'sound waves of the forks vibrate and travel deeply into the body along energy pathways, affecting human physiology and reaching places not easily accessed'. So far, so New Age gibberish. There seems to be no scientific proof that tuning forks can make you look younger, prettier or more rested. It sounds nutty - the kind of thing practised by people who like panpipes and hemp seeds. The UK beauty industryÃ‚Â employs more aÃ‚Â million people andÃ‚Â is worth Ã‚Â£17 bn . I prefer my facials to involve peels, not strange pieces of metal. But while I may be sceptical, I am also, at 37, willing to try anything. Over the past few years, frown lines have begun to appear on my forehead, and my face appears increasingly pale, puffy and bloated. I explain all this to therapist Samara Reid, who's sympathetic. 'What's wonderful about these facials is they improve the appearance of the skin, but also treat the cause of the problem,' she says. 'If you're pale, you probably have poor circulation. The forks can boost blood flow, which will give you a healthier colour.' Samara has been a facial acupuncturist for 20 years, but she has started using the forks on their own and in conjunction with needles. 'I can see my jawline for the first time in a while, and my skin looks plumper and pink, rather than white' The therapies work on the same principle of Chinese acupuncture, which follows the idea that our body's energy - or 'Qi' - flows through 12 main channels called meridians. If this flow is interrupted, it can cause ill health and affect our appearance, causing premature ageing, dry skin and eye bags. Inserting needles or vibrating tuning fork on these trigger points supposedly restores the flow of energy, improving fine lines and circulation, leading to a clearer, rejuvenated complexion. Samara uses them together for a more powerful effect, but for the needle-phobic the forks can be used on their own. Certain forks are designed for different parts of the face and the body - there are dozens of them, with names such as 'Sun', 'Earth' and 'New Moon'. The physical vibrations have an effect on the body, while the sound from the forks is simultaneously soothing. Samara pings one of the forks and puts it up to my ear. The sound is magical, like a xylophone from outer space. She asks me to get on the bed and remove my socks. She explains she will tap my feet with the forks and apply needles to 'bring the energy down for grounding' (whatever that means) before starting on the face and getting the energy flowing all around my body. Samara uses a 'Gold Ohm Unison' tuning fork. She strikes it against a hard disc strapped on her leg, which creates a vibration, before putting the base of the fork on various points on my feet. I can feel a gentle, deep vibration travel through my feet and halfway up my legs. It's a strange, tingly sensation, and builds as she places the fork on more points on my feet. Within two minutes I feel as if I'm floating. She then puts needles in between my toes to 'cleanse the system'. They don't hurt at all. Then she moves to my face. She feels around my jawline and says she can feel I have raised glands. She asks if I get a lot of sore throats, and I say yes. 'The vibration from the forks can help the lymph glands to drain, which will help bring down the swelling,' she says, adding that all she's doing is 'clearing blockages', which will help everything work better. Inserting needles or vibrating tuning fork on these trigger points supposedly restores the flow of energy, improving fine lines and circulation, leading to a clearer, rejuvenated complexion . Marinna finds the physical vibrations have an effect on the body, while the sound from the forks is simultaneously soothing . She also explains that she uses tuning forks to help tighten loose muscle around the jawline. As she puts the base of the 'Earth' fork around my jawline, the vibrations go deep into my head. It feels odd, but also rather lovely. She then puts the forks up to my ears and I hear a clear, deep, bell-like sound that feels as if it's cleaning my mind. All my normal chattering thoughts are gone for a moment. Samara, who is wafting around the room ethereally, as New Aged therapists are wont to do, explains in her soft, slow voice that different forks have different sounds, varying from deep and resonant to high-pitched. She says the 'New Moon' fork is good for wrinkles and crow's feet, because it relaxes the skin. But when she starts talking about how the sounds will 'bring me into alignment with the cycles and rhythms of the cosmos', it feels a step too far. She found the effect was less pronounced the following day - although she still looked better . I begin to feel it is all ridiculous. But then she moves up my face. Samara tells me I have deep lines between my nose and mouth and my cheeks are puffy. She asks if I get a lot of sinus problems. Again, I say yes. She's more thorough than some GPs I've seen. Samara presses the forks along the side of my nose, where the vibrations should help drain the sinuses, and then my eyes, where apparently they will help reduce dark circles. Finally, Samara comes to my forehead. She tells me I have a line forming between my eyebrows, known as the 'suspended sword', which can be caused by fear and concentration. 'Do you frown when you are concentrating?' she asks. I do. 'And do you find yourself feeling frightened quite often?' she asks. Yes! This woman is a mind-reader. And then we're done. It feels as if I've been lying there for a minute, but Samara tells me it's nearly an hour. I feel spaced out. I'm so relaxed it's hard to speak. Apparently, this is normal, the result of feel-good endorphins created when pressure points are stimulated. I'm pleasantly surprised - in the mirror, my face looks less like the Pilsbury Doughboy. I can see my jawline for the first time in a while, and my skin looks plumper and pink, rather than white. The next morning, I take a long, hard look at my face. The effect isn't as pronounced as the day before, but my skin looks smoother and I have more colour. Samara recommends 12 sessions, but most people see a difference after just three or four. At Ã‚Â£90 for an hour, it's not cheap, but it's reminded me of a basic beauty truth: a glowing complexion isn't something to be obtained in an expensive cream - it comes from being healthy inside and out. Samara packs me off with some good advice: drink fresh ginger tea to boost my immune system and try to avoid dairy, which doesn't help if you're prone to congestion, coughs and colds. Maybe I am the hemp seed type after all. I have booked a second appointment. Samara REID, the Hale Clinic, London (020 7631 0156). Experts recommend 12 sessions. At Ã‚Â£90 for an hour, it's not cheap .\"\n",
        "summary = summarize_text(article, model, tokenizer)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "id": "q8ctgA0ah6sB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4356de-136e-46ef-a7ad-1d992f01c7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: A dozen or more metal implements are arranged in neat rows on table next to bed.\n",
            "Tuning forks are made to make different pitched sounds when struck.\n",
            "Some say they are the non-jab equivalent of Botox.\n"
          ]
        }
      ]
    }
  ]
}
